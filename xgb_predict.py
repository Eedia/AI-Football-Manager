import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df = pd.read_csv('EPL_2019_2025.csv')
df['MatchDate'] = pd.to_datetime(df['MatchDate'])
df = df[df['MatchDate'].dt.year >= 2021]  # ìµœê·¼ 3ì‹œì¦Œë§Œ ì‚¬ìš©

#ì‚¬ìš©í•  í”¼ì²˜ ëª©ë¡
features = [
    'HomeElo', 'AwayElo', 'elo_diff',
    'Form3Home', 'Form5Home', 'Form3Away', 'Form5Away',
    'prob_home', 'prob_draw', 'prob_away',
    'h_xg', 'a_xg', 'xG_diff', 'xg_margin', 'xg_ratio',
    'rolling_xg_home_5', 'rolling_xg_away_5',
    'elo_change_home', 'elo_change_away',
    'month', 'weekday'
]

df = df.dropna(subset=features + ['result'])

X = df[features]
y = (df['result'] == 2).astype(int)  # í™ˆìŠ¹ ì—¬ë¶€

# 2. ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. ëª¨ë¸ í•™ìŠµ
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    use_label_encoder=False,
    eval_metric='logloss'
)
model.fit(X_train, y_train)

# 4. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

print("ğŸ¯ Accuracy:", acc)
print("\nğŸ“‹ Classification Report:\n", report)
print("\nğŸ§± Confusion Matrix:\n", cm)

# 5. ëª¨ë¸ ì €ì¥
joblib.dump(model, 'xgb_model.pkl')