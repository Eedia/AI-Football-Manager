{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7910549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb752be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "955a0a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3356\\845658055.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Matches.csv', parse_dates=['MatchDate'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230557 entries, 0 to 230556\n",
      "Data columns (total 56 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Division     230557 non-null  object        \n",
      " 1   MatchDate    230557 non-null  datetime64[ns]\n",
      " 2   MatchTime    99072 non-null   object        \n",
      " 3   HomeTeam     230557 non-null  object        \n",
      " 4   AwayTeam     230557 non-null  object        \n",
      " 5   HomeElo      141597 non-null  float64       \n",
      " 6   AwayElo      141528 non-null  float64       \n",
      " 7   Form3Home    229057 non-null  float64       \n",
      " 8   Form5Home    229057 non-null  float64       \n",
      " 9   Form3Away    229057 non-null  float64       \n",
      " 10  Form5Away    229057 non-null  float64       \n",
      " 11  FTHome       230554 non-null  float64       \n",
      " 12  FTAway       230554 non-null  float64       \n",
      " 13  FTResult     230554 non-null  object        \n",
      " 14  HTHome       175977 non-null  float64       \n",
      " 15  HTAway       175977 non-null  float64       \n",
      " 16  HTResult     175977 non-null  object        \n",
      " 17  HomeShots    114735 non-null  float64       \n",
      " 18  AwayShots    114738 non-null  float64       \n",
      " 19  HomeTarget   113929 non-null  float64       \n",
      " 20  AwayTarget   113932 non-null  float64       \n",
      " 21  HomeFouls    113973 non-null  float64       \n",
      " 22  AwayFouls    113973 non-null  float64       \n",
      " 23  HomeCorners  114363 non-null  float64       \n",
      " 24  AwayCorners  114363 non-null  float64       \n",
      " 25  HomeYellow   119298 non-null  float64       \n",
      " 26  AwayYellow   119299 non-null  float64       \n",
      " 27  HomeRed      119299 non-null  float64       \n",
      " 28  AwayRed      119297 non-null  float64       \n",
      " 29  OddHome      227527 non-null  float64       \n",
      " 30  OddDraw      227527 non-null  float64       \n",
      " 31  OddAway      227527 non-null  float64       \n",
      " 32  MaxHome      202922 non-null  float64       \n",
      " 33  MaxDraw      202922 non-null  float64       \n",
      " 34  MaxAway      202922 non-null  float64       \n",
      " 35  Over25       148398 non-null  float64       \n",
      " 36  Under25      148397 non-null  float64       \n",
      " 37  MaxOver25    148398 non-null  float64       \n",
      " 38  MaxUnder25   148397 non-null  float64       \n",
      " 39  HandiSize    156733 non-null  float64       \n",
      " 40  HandiHome    156475 non-null  float64       \n",
      " 41  HandiAway    156451 non-null  float64       \n",
      " 42  C_LTH        112602 non-null  float64       \n",
      " 43  C_LTA        112602 non-null  float64       \n",
      " 44  C_VHD        112602 non-null  float64       \n",
      " 45  C_VAD        112602 non-null  float64       \n",
      " 46  C_HTB        112602 non-null  float64       \n",
      " 47  C_PHB        112602 non-null  float64       \n",
      " 48  GF3Home      228762 non-null  float64       \n",
      " 49  GA3Home      228762 non-null  float64       \n",
      " 50  GF5Home      227549 non-null  float64       \n",
      " 51  GA5Home      227549 non-null  float64       \n",
      " 52  GF3Away      228731 non-null  float64       \n",
      " 53  GA3Away      228731 non-null  float64       \n",
      " 54  GF5Away      227561 non-null  float64       \n",
      " 55  GA5Away      227561 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(49), object(6)\n",
      "memory usage: 98.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1) CSV 불러오기 & match_id 생성\n",
    "data = pd.read_csv('Matches.csv', parse_dates=['MatchDate'])\n",
    "data = data.reset_index().rename(columns={'index':'match_id'})\n",
    "\n",
    "# 2) 홈/원정 각각 long 포맷으로 전환\n",
    "home = data[['match_id','MatchDate','HomeTeam','FTHome','FTAway']].copy()\n",
    "home = home.assign(\n",
    "    team           = home['HomeTeam'],\n",
    "    goals_for      = home['FTHome'],\n",
    "    goals_against  = home['FTAway'],\n",
    "    venue          = 'Home'\n",
    ")[['match_id','MatchDate','team','goals_for','goals_against','venue']]\n",
    "\n",
    "away = data[['match_id','MatchDate','AwayTeam','FTAway','FTHome']].copy()\n",
    "away = away.assign(\n",
    "    team           = away['AwayTeam'],\n",
    "    goals_for      = away['FTAway'],\n",
    "    goals_against  = away['FTHome'],\n",
    "    venue          = 'Away'\n",
    ")[['match_id','MatchDate','team','goals_for','goals_against','venue']]\n",
    "\n",
    "matches_long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "# 3) 정렬하고 인덱스 재설정 (꼭 필요)\n",
    "matches_long = matches_long.sort_values(['team','MatchDate']).reset_index(drop=True)\n",
    "\n",
    "# 4) 과거 3·5경기 득실 합계 계산 (transform 이용)\n",
    "for N in (3, 5):\n",
    "    # 먼저 “현재 경기” 제외를 위해 shift()\n",
    "    shifted_gf = matches_long.groupby('team')['goals_for']     .shift()\n",
    "    shifted_ga = matches_long.groupby('team')['goals_against'] .shift()\n",
    "\n",
    "    # rolling 합계 계산\n",
    "    matches_long[f'GF{N}'] = (shifted_gf\n",
    "                              .groupby(matches_long['team'])\n",
    "                              .transform(lambda x: x.rolling(N).sum()))\n",
    "    matches_long[f'GA{N}'] = (shifted_ga\n",
    "                              .groupby(matches_long['team'])\n",
    "                              .transform(lambda x: x.rolling(N).sum()))\n",
    "\n",
    "# 5) 홈/Away별로 다시 뽑아서 이름 바꾸기\n",
    "home_stats = (\n",
    "    matches_long[matches_long['venue']=='Home']\n",
    "    .set_index('match_id')[['GF3','GA3','GF5','GA5']]\n",
    "    .rename(columns={\n",
    "        'GF3':'GF3Home','GA3':'GA3Home',\n",
    "        'GF5':'GF5Home','GA5':'GA5Home'\n",
    "    })\n",
    ")\n",
    "away_stats = (\n",
    "    matches_long[matches_long['venue']=='Away']\n",
    "    .set_index('match_id')[['GF3','GA3','GF5','GA5']]\n",
    "    .rename(columns={\n",
    "        'GF3':'GF3Away','GA3':'GA3Away',\n",
    "        'GF5':'GF5Away','GA5':'GA5Away'\n",
    "    })\n",
    ")\n",
    "\n",
    "# 6) map으로 원본 data에 컬럼 추가\n",
    "for col in home_stats.columns:\n",
    "    data[col] = data['match_id'].map(home_stats[col])\n",
    "for col in away_stats.columns:\n",
    "    data[col] = data['match_id'].map(away_stats[col])\n",
    "\n",
    "# 7) 불필요해진 match_id 제거 (선택)\n",
    "data = data.drop(columns=['match_id'])\n",
    "\n",
    "# 8) 결과 확인\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10904799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 전처리\n",
    "# 2-1 데이터 전처리 :데이터 연도 기준 필터링\n",
    "# 프리미어 리그(epl)의 2022~2023연도 데이터를 사용\n",
    "data = data[ data['Division'] == 'E0']   # 프리미어 리그(epl) 데이터 추출\n",
    "\n",
    "# 2-2 데이터 전처리 : 학습에 사용할 column만 추출\n",
    "# 'MatchTime' 임시 제거 \n",
    "columns = ['MatchDate', 'HomeTeam', 'AwayTeam', 'HomeElo', 'AwayElo', 'Form3Home', 'Form5Home', 'Form3Away', 'Form5Away', 'OddHome', 'OddDraw', 'OddAway', 'FTResult', 'MaxHome', 'MaxDraw', 'MaxAway', 'Over25', 'Under25', 'MaxOver25', 'MaxUnder25', 'HandiSize', 'HandiHome', 'HandiAway', 'GF3Home', 'GA3Home', 'GF5Home', 'GA5Home', 'GF3Away', 'GA3Away', 'GF5Away', 'GA5Away'\n",
    "]\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b287c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3 데이터 전처리 : 결측치 확인\n",
    "data.isnull().sum()\n",
    "\n",
    "# 결측치 있는 행 제거\n",
    "# data = data.dropna(subset=['HomeElo', 'AwayElo']).reset_index(drop=True)\n",
    "\n",
    "data = data.dropna(subset=columns).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a60c4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-4 데이터 전처리 : Standardize(표준화), OneHotEncoding(원-핫 인코딩)\n",
    "log_columns = ['HomeElo', 'AwayElo', 'OddHome', 'OddDraw', 'OddAway', 'MaxHome', 'MaxDraw', 'MaxAway', 'Over25', 'Under25', 'MaxOver25', 'MaxUnder25', 'HandiHome', 'HandiAway'] # 로그 변환할 columns\n",
    "standarize_columns = ['HomeElo', 'AwayElo', 'OddHome', 'OddDraw', 'OddAway', 'Form3Home', 'Form5Home', 'Form3Away', 'Form5Away', 'HandiSize', 'HandiHome', 'HandiAway', 'GF3Home', 'GA3Home', 'GF5Home', 'GA5Home', 'GF3Away', 'GA3Away', 'GF5Away', 'GA5Away']  # 표준화할 columns\n",
    "encoding_columns = ['HomeTeam', 'AwayTeam']  # 원-핫 인코딩할 columns\n",
    "\n",
    "# 분산이 큰 배당률 관련 columns와 Elo columns는 표준화 전에 log scale을 먼저 적용\n",
    "data[log_columns] = np.log1p(data[log_columns])\n",
    "\n",
    "# Pipeline에서 전처리 해줄 ColumnsTransformer 정의\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standardize', StandardScaler(), standarize_columns),  # 표준화\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True), encoding_columns)  # 원-핫 인코딩\n",
    "    ],\n",
    "    remainder='passthrough'  # 나머지 컬럼은 그대로 유지\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff709ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MatchDate'] = pd.to_datetime(data['MatchDate'])  # MatchDate를 datetime 형식으로 변환\n",
    "\n",
    "data_train = data[(data['MatchDate'] < '2025-01-01')]   # 학습 데이터 : 24/25 시즌제외 모든 데이터 추출\n",
    "data_test = data[(data['MatchDate'] >= '2025-01-01')]   # 테스트 데이터 : 24/25 시즌 데이터 추출\n",
    "\n",
    "# # MatchDate 제거\n",
    "data_train = data_train.drop(columns=['MatchDate']) \n",
    "data_test = data_test.drop(columns=['MatchDate'])  \n",
    "\n",
    "#  featuer, target 분리\n",
    "\n",
    "X_train = data_train.drop(columns=['FTResult'])  # Feature columns\n",
    "X_test = data_test.drop(columns=['FTResult'])  # Feature columns\n",
    "y_train = data_train['FTResult'].map({'H':0, 'D':1, 'A':2})  # Target column\n",
    "y_test = data_test['FTResult'].map({'H':0, 'D':1, 'A':2})  # Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0bea1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 테스트 데이터 분리\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y,\n",
    "#     test_size=0.2,           # 20 % 검증(또는 0.25 등)\n",
    "#     random_state=42,         \n",
    "#     stratify=y               # 클래스 비율 유지 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86c3ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lightgbm = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),  # 전처리 단계\n",
    "        ('classifier', LGBMClassifier(\n",
    "            objective='multiclass',  # 다중 클래스 분류\n",
    "            num_class=3,  # 홈 승, 무승부, 원정 승\n",
    "            n_estimators   = 1200,\n",
    "            learning_rate  = 0.03,\n",
    "            max_depth      = -1,             # 자동\n",
    "            num_leaves     = 63,             # 2^(max_depth) -1 근사\n",
    "            colsample_bytree = 0.8,\n",
    "            subsample        = 0.8,\n",
    "            reg_alpha        = 0.1,\n",
    "            reg_lambda       = 1.0,\n",
    "            random_state     = 42,\n",
    "            class_weight     = 'balanced'\n",
    "        ))  # LightGBM \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d27ca6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_lightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:654\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    651\u001b[0m     )\n\u001b[0;32m    653\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 654\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:588\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m    582\u001b[0m step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    583\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39mstep_idx,\n\u001b[0;32m    584\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[0;32m    585\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mraw_params,\n\u001b[0;32m    586\u001b[0m )\n\u001b[1;32m--> 588\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\joblib\\memory.py:326\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:1551\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1551\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1553\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1554\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1555\u001b[0m         )\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1031\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[1;32m-> 1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1135\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[1;34m(self, Xs, n_samples)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output_:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# dtype conversion if necessary.\u001b[39;00m\n\u001b[1;32m-> 1135\u001b[0m         converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1136\u001b[0m             check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1137\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[0;32m   1138\u001b[0m         ]\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sparse output, all columns should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe a numeric or convertible to a numeric.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1143\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1136\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output_:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# dtype conversion if necessary.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1136\u001b[0m             \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[0;32m   1138\u001b[0m         ]\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sparse output, all columns should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe a numeric or convertible to a numeric.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1143\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    927\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    928\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    929\u001b[0m )\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 931\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    934\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)"
     ]
    }
   ],
   "source": [
    "model_lightgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea01c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\project\\module_project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_lightgbm  = model_lightgbm.predict(X_test)\n",
    "y_prob_lightgbm  = model_lightgbm.predict_proba(X_test)   # shape = (n_samples, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf78623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5036255767963085\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62       694\n",
      "           1       0.28      0.20      0.24       367\n",
      "           2       0.49      0.48      0.49       456\n",
      "\n",
      "    accuracy                           0.50      1517\n",
      "   macro avg       0.45      0.45      0.45      1517\n",
      "weighted avg       0.48      0.50      0.49      1517\n",
      "\n",
      "Log-loss : 1.2184625661886839\n",
      "Confusion Matrix\n",
      " [[471 104 119]\n",
      " [188  74 105]\n",
      " [155  82 219]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_lightgbm))\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred_lightgbm))\n",
    "\n",
    "# (선택) 로그-로스 — 다중 클래스 확률 평가\n",
    "print(\"Log-loss :\", log_loss(y_test, y_prob_lightgbm))\n",
    "\n",
    "# (선택) 혼동 행렬\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_test, y_pred_lightgbm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
