# 모델 학습 및 사용법

**epl 승부 예측을 위한 머신러닝 모델**

<br>

## 목차
- [학습 데이터 셋](#학습-데이터-셋)
- [라이브러리](#라이브러리)
- [feature](#feature)
- [데이터 전처리](#데이터-전처리)
- [1차 학습](#1차-학습)
- [2차 학습](#2차-학습)


<br>

## 학습 데이터 셋
- Matches.csv
    - 2005년 부터 2025년도까지의 축구 5대 리그에 대한 데이터
    - 출처 : <a href="https://www.kaggle.com/datasets/adamgbor/club-football-match-data-2000-2025">kaggle</a>
- soccerdata 라이브러리
    - UnderStat 사이트에서 정보를 얻어온다.    
    <a href="https://understat.com/league/EPL/2023">사이트 링크</a>

<br>

## 라이브러리
- 'pandas' : '2.3.0'
- 'numpy' : '2.0.2'
- 'matplotlib' : '3.9.4'
- 'scikit-learn' : '1.6.1'
- 'soccerdata' : '1.8.7'

<br>

## feature
- `_l5` **- 최근 5경기 간**
- `Form3Home` **- 최근 3경기간 획득 point**
- `_diff` **- 해당 feature의 홈팀과 원정팀의 값차이**

<br>

| 구분             | 포함된 Feature                                                                                                                                                                  | 핵심 목적                       |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- |
| **메타 정보**      | `MatchDate`, `HomeTeam`, `AwayTeam`                                                                                                                                          | 학습 · 테스트 스플릿 / 팀 고유 효과 인코딩  |
| **전력 지표**      | `HomeElo`, `AwayElo`, `elo_diff`                                                                                                                                  | 팀 기본 실력 지표(Elo) |
| **폼(최근 성적)**   | `Form3Home`, `Form5Home`, `Form3Away`, `Form5Away`                                                                                                                           | 최근 승점 수로 팀의 추세 파악              |
| **득 · 실점 추세**  | `GF3Home`, `GA3Home`, `GF5Home`, `GA5Home`, <br>`GF3Away`, `GA3Away`, `GF5Away`, `GA5Away`                                                                                    | 최근 경기에서 홈팀과 원정팀이 넣은 골 수, 실점 수(F: 골 수, A: 실점 수)            |
| **xG 지표**      | `h_xg`, `a_xg`, `xG_diff`, `xg_margin`, `xg_ratio`, <br>`rolling_xg_home_5`, `rolling_xg_away_5`                                                                                        | xG(Expected Goals), 기대 득점 수준 & 양팀 비교, margin(diff의 절댓값), ratio(홈과 원정팀의 xG비율) 백분율)            |           |
| **타깃 변수**      | `FTResult`                                                                                                                                                                   | 타겟 레이블(H, A),  H-홈팀 승리, A-원정팀 승리               |


<br><br>

## 데이터 전처리

- Matchees.csv
    - 경기 일자, 홈팀, 원정팀, ELO정보, Form3Home 등 xG를 제외한 중요한 feature가 모여있는 csv 파일이다.

- xg_data.ipynb
    - soccerdata 라이브러리를 통해서 xG 데이터를 가져온다.
    - 가져온 xG 데이터를 이용해 파생 feature를 계산한다.
    - csv파일로 저장한다. -> xg_data.csv

<br>

- xg_data.csv 
    - xG에 관한 데이터가 담겨있는 csv파일

<br>

- data_final.csv 
    - Matchees.csv에서 필요한 column과 xg_data.csv를 합친 데이터
    - encoding만 완료될 시 바로 학습할 수 있는 전체 데이터셋이다.
    
<br>

- encoding 필요한 columns : ['HomeTeam', 'AwayTeam'] 
    - 특정 팀이 Home일 때 Away일 때를 비교하기 위해 OneHotEncoding을 진행한다.

<br>


## 1차 학습
**preprocessing_learning_동은.ipynb 참고**

데이터가 3000개 정도로 적은 편이기에 일부러 약간의 과적합을 유도하고 ensemble 중 stacking 기법을 이용해 많은 학습을 시켰다.  
<br>
<image src='./image/first learning.png'>

과적합을 조금만 유도하기 위해 가벼운 학습을 하는 lightgbm과 max_iter를 낮춘 logistic을 사용했고,
마지막에도 3개의 모델이 학습한 결과를 종합해 logistic으로 가볍게 파라미터를 두어 재학습했다.

<br>

<image src='./image/first learning result.png'>

이 때는 승부 예측이 승, 패, 무승부로 다중클래스였다. 하지만 정확도는 58% 정도였고, 학습 모델들이 이진분류나 다중클래스 분류에도 맞지 않았다.  
또한 무승부의 확률은 승리 확률과 패배 확률이 비등한 경우에 높아져야하는데 승리, 무승부, 패배를 동시에 예측을 하면 아무리 승리 확률과 패배 확률이 비슷해져도 무승부 확률은 최대로 33%만 나와 이 두 확률을 넘어설 수는 없었다.  
그래서 무승부는 아예 예측 타겟에서 제외하고 학습하기 시작했고, 승리와 패배만을 예측하는 이진분류의   정확도가 훨씬 높았다.

<br>

## 2차 학습 

**test_model.ipynb 참고**

### ExtraTreesClassifier :
  feature 수는 많고 데이터 수는 적을 때 과적합 방지에 용이한 ensemble 모델,  
  `model_final.pkl` : 학습 완료된 모델 파일
    
- ExtraTreesClassifier 채택 이유
    - 1차 학습을 통해서 이진 분류에 적합한 모델과 적은 데이터셋으로도 학습이 가능하면서도 과적합이 일어나지 않는 모델이 필요하다는 것을 깨달았다.
    - 이진 분류에서 높은 정확도를 보이는 Random Forest Classifier는 BootStrap Sampling이라는 복원 추출 기법을 사용하기에 데이터 수가 적은 상황에서 높은 정확도르 보이지만 과적합을 초래할 위험이 있다.          
    그래서 BootStrap Sampling을 사용하지 않으면서 Random Forest Classifier의 학습 정확도가 더 업그레이드 된 버전인 Extra Trees Classifier를 사용했다.
    - 또한 Extra Trees Classifier는 Random Forest Classifier에 비해서 특성의 중요도를 더 높게 평가한다. 그래서 핵심 fature를 가려내지 모르는 상황에서 대량의 feature를 넣고 학습시켜도 핵심 feature를 잘 발견하여 학습하기에 현재 데이터셋 상황에서 가장 적절했다.  

<br>

- 학습 방식 :
    - Tree 방식이기 때문에 표준화, 정규와 같은 데이터 전처리는 의미가 거의 없다. 따라서 HomeTeam, AwayTeam만 OneHot Encoding을 진행하고,  ExtraTreesClassifier를 통해 학습했다.

    - ExtraTreesClassifier는 여러 개의 독립된 랜덤 트리를 만들고 모든 트리의 결과를 평균을 내는 방식을 사용한다.  
각 트리를 충분히 학습시키고 마지막에 랜덤한 결과를 산출하면 이 결과를 모아 평균을 낸다.   
ExtraTreesClassifier는 충분히 학습한 트리가 랜덤한 결과를 내놓은 것 같아도 근거가 있어서 해당 결과가 나왔을 것이라는 가설을 통해 트리들의 결과를 모아 평균을 낸다. 이는 실제로도 좋은 결과를 만들어낸다.   

    - 마치 한 분야에 대한 수백명의 전문가를 모아놓고, 이들에게 같은 문제를 고민하게 만들면 평균적으로 같은(좋은) 결과에 수렴하는 것과 같은 원리이다.


### 파라미터 
- 파라미터는 ReandomizedSearchCV를 통해서 대략적으로 정하고 이후에 반복 미세 조정으로 현재의 파라미터 값을 얻었다.

<br>

| 파라미터   | 값                                                                                   |
| ------ | ------ | 
| n_estimators  | 1900  |
|  max_depth  |  10 |
| max_features   |  0.25 |
| min_samples_leaf   | 15  |
| n_jobs   |  -1 |
|  class_weight  |  balanced_subsample |
|  random_state  |  42 |

<br>

### CalibratedClassifierCV :

학습으로 만들어진 모델의 정확도가 0.9가 나온다고 하더라도 실제 테스트 케이스에서는 정확도가 낮게 나오는 경우가 있다.    
이런 불일치를 교정하기 위해서 학습 데이터와 실제 라벨을 이용해 확률을 교정해준다.    
이는 모델의 accuracy나 performence를 올려주는 것이 아니라 모델의 신뢰도를 높이는 교정과정이다.

<br> 

예시를 들어보도록 하자.

| 샘플 | 모델 예측 확률 (긍정 : 1) | 실제 결과 |
| -- | ----------------- | ----- |
| 1  | 0.95              | 1     |
| 2  | 0.90              | 1     |
| 3  | 0.85              | 1     |
| 4  | 0.80              | 0     |
| 5  | 0.75              | 0     |
| 6  | 0.70              | 0     |

위 경우에서 1~4에 해당하는 예측 확률은 0.875이다. 하지만 실제로 맞은 경우는 4개 중 3개인 75%이다.
이러한 차이가 커질수록 모델의 신뢰도가 떨어진다. 따라서 모델이 실제로 예측한 값을 바꾸지는 않지만 내부적으로   
모델이 예측한 확률 값만을 바꾸어 0.875를 실제 결과인 75%로 교정하는 것이다.


### 학습 결과

학습 과정은 ExtraTreesClassifier로 학습을 하고 CalibratedClassifierCV로 교정을 거친 뒤 계산한 확률 값 return한다. 따라서 GPT에게 질문 했을 때 알려주는 승부 예측 확률은 CalibratedClassifierCV로 교정된 확률이다.


<br>

### 예측

예측 데이터는 soccerdata 라이브러리를 통해 UnderStat 사이트에 접근하여 팀의 최신 정보들을 가져와 학습 feature와 동일한 구성의 데이터 프레임으로 제작한다. 따라서 과거의 데이터를 통하여 학습한 모델로 가장 최근 데이터를 넣어 미래 경기 결과를 예측할 수 있다.